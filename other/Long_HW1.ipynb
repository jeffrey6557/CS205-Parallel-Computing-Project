{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Homework 1\n",
    "\n",
    "## AMPTH 207: Stochastic Methods for Data Analysis, Inference and Optimization\n",
    " \n",
    "**Due Date:** Thursday, Febrary 23rd, 2017 at 11:59pm\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Upload your final answers as well as your iPython notebook containing all work to Canvas.\n",
    "\n",
    "- Structure your notebook and your work to maximize readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premise\n",
    "\n",
    "In supervised machine learning, a function that maps certain input data to a set of outputs is inferred from a labelled dataset called the training set, and the resulting learnt funtion is then used to make predictions on unseen new examples of the dataset (the test set).\n",
    "\n",
    "The goal of this homework is to construct a classifier known as the single-hidden-layer Multi-Layer Perceptron (MLP), an artificial neural netwok. You are asked to train the classifier using mini-batch gradient descent, validate it, and then apply it to a test dataset to make predictions. We will use the [*MNIST* dataset](https://en.wikipedia.org/wiki/MNIST_database), which consists of 70,000 images of handwritten digits, each of which is 28x28 pixels. You can use the first 50,000 images as the training set, the next 10,000 images as the validation set, and the last 10,000 images as the test set.\n",
    "\n",
    "You will proceed in 2 steps (each step is a problem) to build the MLP. Please use Theano to program the classifiers.\n",
    "\n",
    "## Problem 1. Stochastic gradient descent for the logistic regresion\n",
    "\n",
    "First, build a logistic regression classifier whose input is the array of pixel values in one image, and whose output is the most likely class of the vector. In order to familiarize yourself with the dataset, plot some of the images beforehand, and think about the pixel values as features of the input vector.\n",
    "\n",
    "### Part A\n",
    "\n",
    "Using the softmax formulation, write a Theano expression graph that:\n",
    "* Calculates the probability of a target element belonging to class $i$ (i.e., the probability that a given image represents a digit between 0 and 9).\n",
    "* Maximizes it over all classes, and computes the cost function using an L2 regularization approach\n",
    "* Minimizes the resulting cost function using mini-batch gradient descent. How long does it take for your code to train with 50,000 training examples of the dataset?\n",
    "\n",
    "*Hint: Use a batch size of 256 examples, a learning rate $\\eta = 0.1$, and a regularization factor $\\lambda=0.01$*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import datetime\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import six.moves.cPickle as pickle\n",
    "dataset='mnist.pkl.gz'\n",
    "with gzip.open(dataset, 'rb') as f:\n",
    "        try:\n",
    "            train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "        except:\n",
    "            train_set, valid_set, test_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.441301665703 0.441334908689 0:00:47.881992\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1 # Learning rate\n",
    "lambdas = 0.01 # regularization factor \n",
    "x = T.dmatrix('x')\n",
    "y = T.lvector('y')\n",
    "w = theano.shared(np.random.randn(train_set[0].shape[1],len(np.unique(train_set[1]))),name='w',borrow=True)\n",
    "b = theano.shared(value=np.zeros((len(np.unique(train_set[1])),),dtype=theano.config.floatX),name='b',borrow=True)\n",
    "p_y_given_x = T.nnet.softmax(T.dot(x, w) + b)   # Probability that target belongs to class i\n",
    "prediction = T.argmax(p_y_given_x, axis=1)      # The prediction of the model (class whose probability is maximal)\n",
    "loss = -T.mean(T.log(p_y_given_x)[T.arange(y.shape[0]), y])  # Loss function\n",
    "cost = loss.mean() + lambdas * (w ** 2).sum()      # The cost to minimize\n",
    "gw = T.grad(cost=cost, wrt=w)\n",
    "gb = T.grad(cost=cost, wrt=b)\n",
    "train = theano.function(inputs=[x,y], outputs=[prediction, loss],\n",
    "          updates=((w, w - eta * gw), (b, b - eta * gb)),name='train')\n",
    "validate = theano.function(inputs=[x,y],outputs=[prediction, loss],name='validate')\n",
    "test = theano.function(inputs=[x,y],outputs=[prediction, loss],name='test')\n",
    "predict = theano.function(inputs=[x], outputs=prediction, name='predict')\n",
    "# Train\n",
    "n_epochs = 100\n",
    "batch_size = 256    # size of the minibatch\n",
    "n_train_batches = train_set[0].shape[0] // batch_size\n",
    "n_valid_batches = valid_set[0].shape[0] // batch_size\n",
    "n_test_batches = test_set[0].shape[0] // batch_size\n",
    "error_train = []   \n",
    "error_valid = []\n",
    "error_new, error_old, i = 1,0,0\n",
    "time1=datetime.datetime.now()\n",
    "while abs(error_old - error_new) > 1e-4: ## early stop\n",
    "    error_old = error_new\n",
    "    order = np.random.permutation(train_set[0].shape[0])\n",
    "    permutex = train_set[0][order]\n",
    "    permutey = train_set[1][order]\n",
    "    error_valid_int = []\n",
    "    for index in range(n_train_batches):\n",
    "        # Now for the update we only use one mini-batch at a time\n",
    "        pred, err = train(permutex[index * batch_size: (index + 1) * batch_size], \\\n",
    "                          permutey[index * batch_size: (index + 1) * batch_size])\n",
    "        error_train.append(err)  # save the train error for this batch\n",
    "        errores = []             \n",
    "        # Now we check the performance on the validation set, every 2 batches.\n",
    "        if (index%2 == 0):\n",
    "            for j in range(n_valid_batches):\n",
    "                pred_val, err_val = validate(valid_set[0][j * batch_size: (j + 1) * batch_size], \\\n",
    "                              valid_set[1][j * batch_size: (j + 1) * batch_size])\n",
    "                errores.append(err_val)\n",
    "            # We get the validation error as the average over batches\n",
    "            this_error = np.mean(errores)\n",
    "            error_valid.append(this_error)\n",
    "            error_valid_int.append(this_error)            \n",
    "    error_new = np.mean(error_valid_int)\n",
    "    i=i+1\n",
    "    if(i==n_epochs):break ## compulsory stop\n",
    "time2=datetime.datetime.now()\n",
    "print(i,error_old,error_new,time2-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "* Evaluate the validation loss function periodically as you train the classifier and plot it as a function of the epoch. Plot this loss function for several values of the regularization factor.\n",
    "* When should you stop the training for different values of $\\lambda$? Give an approximate answer supported by using the plots.\n",
    "* Select what you consider the best regularization factor and predict the classes of the test set. Compare with the given labels. What is the test error that you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAF9CAYAAAB7x3ACAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\no716AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2614c47c748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(np.arange(len(error_valid)),np.array(error_valid),marker='.')\n",
    "plt.suptitle('lambda = 0.01')\n",
    "plt.axis('tight')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.3768324747 0.376804462154 0:00:50.470418\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1 # Learning rate\n",
    "lambdas = 0.005 # regularization factor \n",
    "x = T.dmatrix('x')\n",
    "y = T.lvector('y')\n",
    "w = theano.shared(np.random.randn(train_set[0].shape[1],len(np.unique(train_set[1]))),name='w',borrow=True)\n",
    "b = theano.shared(value=np.zeros((len(np.unique(train_set[1])),),dtype=theano.config.floatX),name='b',borrow=True)\n",
    "p_y_given_x = T.nnet.softmax(T.dot(x, w) + b)   # Probability that target belongs to class i\n",
    "prediction = T.argmax(p_y_given_x, axis=1)      # The prediction of the model (class whose probability is maximal)\n",
    "loss = -T.mean(T.log(p_y_given_x)[T.arange(y.shape[0]), y])  # Loss function\n",
    "cost = loss.mean() + lambdas * (w ** 2).sum()      # The cost to minimize\n",
    "gw = T.grad(cost=cost, wrt=w)\n",
    "gb = T.grad(cost=cost, wrt=b)\n",
    "train = theano.function(inputs=[x,y], outputs=[prediction, loss],\n",
    "          updates=((w, w - eta * gw), (b, b - eta * gb)),name='train')\n",
    "validate = theano.function(inputs=[x,y],outputs=[prediction, loss],name='validate')\n",
    "test = theano.function(inputs=[x,y],outputs=[prediction, loss],name='test')\n",
    "predict = theano.function(inputs=[x], outputs=prediction, name='predict')\n",
    "# Train\n",
    "n_epochs = 100\n",
    "batch_size = 256    # size of the minibatch\n",
    "n_train_batches = train_set[0].shape[0] // batch_size\n",
    "n_valid_batches = valid_set[0].shape[0] // batch_size\n",
    "n_test_batches = test_set[0].shape[0] // batch_size\n",
    "error_train = []   \n",
    "error_valid = []\n",
    "error_new, error_old, i = 1,0,0\n",
    "time1=datetime.datetime.now()\n",
    "while abs(error_old - error_new) > 1e-4: ## early stop\n",
    "    error_old = error_new\n",
    "    order = np.random.permutation(train_set[0].shape[0])\n",
    "    permutex = train_set[0][order]\n",
    "    permutey = train_set[1][order]\n",
    "    error_valid_int = []\n",
    "    for index in range(n_train_batches):\n",
    "        # Now for the update we only use one mini-batch at a time\n",
    "        pred, err = train(permutex[index * batch_size: (index + 1) * batch_size], \\\n",
    "                          permutey[index * batch_size: (index + 1) * batch_size])\n",
    "        error_train.append(err)  # save the train error for this batch\n",
    "        errores = []             \n",
    "        # Now we check the performance on the validation set, every 2 batches.\n",
    "        if (index%2 == 0):\n",
    "            for j in range(n_valid_batches):\n",
    "                pred_val, err_val = validate(valid_set[0][j * batch_size: (j + 1) * batch_size], \\\n",
    "                              valid_set[1][j * batch_size: (j + 1) * batch_size])\n",
    "                errores.append(err_val)\n",
    "            # We get the validation error as the average over batches\n",
    "            this_error = np.mean(errores)\n",
    "            error_valid.append(this_error)\n",
    "            error_valid_int.append(this_error)           \n",
    "    error_new = np.mean(error_valid_int)\n",
    "    i=i+1\n",
    "    if(i==n_epochs):break ## compulsory stop\n",
    "time2=datetime.datetime.now()\n",
    "print(i,error_old,error_new,time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAF9CAYAAAB7x3ACAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkoSBQJIkYSCQJEkYCCRJEvD/ARobizExwLjvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x261013d4400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(error_valid)),np.array(error_valid),marker='.')\n",
    "plt.suptitle('lambda = 0.005')\n",
    "plt.axis('tight')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.723924233302 0.723847872054 0:00:36.418587\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1 # Learning rate\n",
    "lambdas = 0.05 # regularization factor \n",
    "x = T.dmatrix('x')\n",
    "y = T.lvector('y')\n",
    "w = theano.shared(np.random.randn(train_set[0].shape[1],len(np.unique(train_set[1]))),name='w',borrow=True)\n",
    "b = theano.shared(value=np.zeros((len(np.unique(train_set[1])),),dtype=theano.config.floatX),name='b',borrow=True)\n",
    "p_y_given_x = T.nnet.softmax(T.dot(x, w) + b)   # Probability that target belongs to class i\n",
    "prediction = T.argmax(p_y_given_x, axis=1)      # The prediction of the model (class whose probability is maximal)\n",
    "loss = -T.mean(T.log(p_y_given_x)[T.arange(y.shape[0]), y])  # Loss function\n",
    "cost = loss.mean() + lambdas * (w ** 2).sum()      # The cost to minimize\n",
    "gw = T.grad(cost=cost, wrt=w)\n",
    "gb = T.grad(cost=cost, wrt=b)\n",
    "train = theano.function(inputs=[x,y], outputs=[prediction, loss],\n",
    "          updates=((w, w - eta * gw), (b, b - eta * gb)),name='train')\n",
    "validate = theano.function(inputs=[x,y],outputs=[prediction, loss],name='validate')\n",
    "test = theano.function(inputs=[x,y],outputs=[prediction, loss],name='test')\n",
    "predict = theano.function(inputs=[x], outputs=prediction, name='predict')\n",
    "# Train\n",
    "n_epochs = 100\n",
    "batch_size = 256    # size of the minibatch\n",
    "n_train_batches = train_set[0].shape[0] // batch_size\n",
    "n_valid_batches = valid_set[0].shape[0] // batch_size\n",
    "n_test_batches = test_set[0].shape[0] // batch_size\n",
    "error_train = []   \n",
    "error_valid = []\n",
    "error_new, error_old, i = 1,0,0\n",
    "time1=datetime.datetime.now()\n",
    "while abs(error_old - error_new) > 1e-4: ## early stop\n",
    "    error_old = error_new\n",
    "    order = np.random.permutation(train_set[0].shape[0])\n",
    "    permutex = train_set[0][order]\n",
    "    permutey = train_set[1][order]\n",
    "    error_valid_int = []\n",
    "    for index in range(n_train_batches):\n",
    "        # Now for the update we only use one mini-batch at a time\n",
    "        pred, err = train(permutex[index * batch_size: (index + 1) * batch_size], \\\n",
    "                          permutey[index * batch_size: (index + 1) * batch_size])\n",
    "        error_train.append(err)  # save the train error for this batch\n",
    "        errores = []             \n",
    "        # Now we check the performance on the validation set, every 2 batches.\n",
    "        if (index%2 == 0):\n",
    "            for j in range(n_valid_batches):\n",
    "                pred_val, err_val = validate(valid_set[0][j * batch_size: (j + 1) * batch_size], \\\n",
    "                              valid_set[1][j * batch_size: (j + 1) * batch_size])\n",
    "                errores.append(err_val)\n",
    "            # We get the validation error as the average over batches\n",
    "            this_error = np.mean(errores)\n",
    "            error_valid.append(this_error)\n",
    "            error_valid_int.append(this_error)           \n",
    "    error_new = np.mean(error_valid_int)\n",
    "    i=i+1\n",
    "    if(i==n_epochs):break ## compulsory stop\n",
    "time2=datetime.datetime.now()\n",
    "print(i,error_old,error_new,time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAF9CAYAAAB7x3ACAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3X+cXHV97/HXh2x+kERXA0xAUCo/BCwlskugMfjr4q2t\n2vTW1epYr49eva0p2l63VaoP29J61dYWob/khlor/sC5l+KopLVFsVYaKkZ2EayAWoQigSzkh0uA\nkJ/f+8eZJbOTze7O7szOnjOv5+Mxjz3nzDkz3/myZN9zzuf7PZFSQpIkdbejOt0ASZLUeQYCSZJk\nIJAkSQYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJDaKiK+FhGXz9f3iYh7I+I329EmSfli\nIJDUURGxOCI+GhHbImJXRFwXEaVpHPf2WqDZHRG3RMTqhuc/EREHGx5fat8nkfLNQCCp0/4MeBUw\nALwYeBbwuckOiIjXAx8BLgXOBW4HboiIYxt2/UdgJXB87VFuaculAjEQSHMoIt4UEd+KiEcj4qGI\nuCYijqt7/iW1b7I/ExHDEfFERNwYEcdFxM9FxJ0RMVo7bknDy/dExF9GxI8j4pGIeH/Dex8XERtr\nr3lPRLxxgvYNRsQdEfFYRNxf++a+tE3dQUQ8HXgLMJhS+npK6TbgfwBrI+L8SQ4dBK5KKX0qpXQ3\nsB54ovZa9faklB5JKT1ce4y243NIRWAgkOZWD/C7wDnALwAnA5+YYL9LgYuBNcBzgGuB3wTeALwS\n+BngNxqO+RVgH7C6tu9vRcRb657/JHAi8BLgtbXXP67hNQ7UXvf5wJuBlwF/MtkHiogv1U71H+nx\nnUkO7yfrk6+ObUgpfQ+4v/bZJ3q/hbXj6o9JwI0THPPSiBiJiLsj4sqIWDHZZ5G6WU+nGyB1k5TS\n1XWr90XEO4FvRsTSlNITY7sB70sp3QIQER8HPgScklL6z9q268j+WP9p3evdn1L6rdryDyLiHLJv\n0h+PiOcBPwucl1Iarr3GW4G7Gtr3F/WvFxG/B/wf4B2TfKy3AkdP8vy+SZ47HtibUnq0YftI7bmJ\nHAssqO3TeMwZdev/SHbp4V7gVOCPgC9FxJrkfd+lwxgIpDkUEf1k3/5XAc/k0Fm65wB31+1a/616\nBHhiLAzUbRtXRAfc0rD+DbKzBAGcBewbCwOQfROPiB83tO/lwHuAM4Gnk/0bsTgilqSUnpzoM6WU\nHjrCx+2olNK1davfrZ2puAd4KfC1jjRKmse8ZCDNkdq1+H8Cfgy8ETgP+MXa04sadq//Vp04/Ft2\norn/f6f8RhwRJwMbgW8DrwH6gLcfoX31x83mksFWYFGtlqDeytpzE9lGdmljZRPHkFK6t3bsaZO0\nR+paniGQ5s6ZwArgvSmlLQBTFM4164KG9TXAD1JKKSLuJis67E8pDdXe+wzgGXX79wORUnrX2IaI\neMM03nc2lwyGgP3ARcDn69r1HLIzHIdJKe2LiKHaMdfXjona+l9MdExtn5OAY4B5eUZD6jQDgTR3\n7gf2Ar8ZERuAnyIrMGwUM3z950TEZcBfk/1xfwdZDQEppe9HxA3AX0fEr5N9w76CrDJ/zH8AC2sT\nFW0ELgTeNtWbzuaSQUrp0VqNxOURsRPYRfZH/eaU0uax/SLiq8DnUkpX1jZdDlxdCwaba59zKXB1\nbf9lZJdmPkd21uA04MPA94EbZtpeqci8ZCC111On6lNK28hGArwW+C5wCfDbkx3T5Pt8iuyb+mbg\nL4ErUkp/U7fPrwBbgH8BrgOuAh6ua98dwG/V2vUdsjH775lBW5o1CPx9rU3/AjxINidBveeSFROO\ntfVa4F3A+4HbyEZtvCKl9EhtlwO1bV8Evgd8DPgW8OKU0mRnLKSuFRbbSpIkzxBIkiQDgSRJMhBI\nkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBI\nkiQMBJIkCQOBJEnCQCBJkoCeTjdgKhFxDPAK4D7gyc62RpKkXFkC/ARwQ0pp+2Q7zvtAQBYGrul0\nIyRJyrFfBj472Q55CAT3ZT8+w6pVZ/G3f9vRthTO4OAgV1xxRaebUTj2a/vYt+1hv7ZHp/v1rrvu\n4k1vehM89bf0yPIQCJ4EOPXUs/jyl/solTrdnGLp7e2lr6+v080oHPu1fezb9rBf22Me9euUl9xz\nU1T4zndiGJAkqU1yEwietJxQkqS2yU0g2LOn0y2QJKm4DARdrlwud7oJhWS/to992x72a3vkqV8j\npdTpNkwqIvqAoUsuGeLDH54XhRmSJOXC8PAw/f39AP0ppeHJ9s3NGQJrCCRJah8DgSRJyk8gsIZA\nkqT2yU0guO46uPBCePjhTrdEkqTiyU0gePxxuPlmeM1rOt0SSZKKJzeBYMxDD3W6BZIkFU/uAsEJ\nJ3S6BZIkFU8ebm4EwOLFcN55UK12uiWSJBVPbgLBWWfBpk2dboUkScWUm0sGu3d3ugWSJBVXbgKB\nExNJktQ+BgJJkpSfQOAlA0mS2ic3geDRR52pUJKkdslNIABnKpQkqV1yFQjAmQolSWqH3AUCZyqU\nJKn1OhYIIqIaETsi4trpHtPX50yFkiS1QyfPEPwZ8N+bOeDjH4dSqU2tkSSpi3UsEKSUbgIea+aY\nx5raW5IkTVeuaggMBJIktUfTgSAiXhQR10fElog4GBHrJtjn7RFxb0TsjohbImJ1KxprIJAkqT1m\ncoZgGfBt4GIgNT4ZEa8HPgJcCpwL3A7cEBHHzqKdgIFAkqR2aToQpJT+KaX0+ymlLwIxwS6DwFUp\npU+llO4G1gNPAG+ZYN84wmtM6F3vcrZCSZLaoaU1BBGxEOgHvjq2LaWUgBuBNQ37fgX4f8DPRcT9\nEXHBVK+/fbuzFUqS1A49LX69Y4EFwEjD9hHgjPoNKaX/2txLDwK9ANx2G6xbB+VymXK5PNO2SpJU\nGJVKhUqlMm7b6OjotI9vdSBooyuAPgDOPReuv76zrZEkaT6Z6Evy8PAw/f390zq+1YFgG3AAWNmw\nfSWwdTYvfPTR0NMD55zjbIWSJLVaS2sIUkr7gCHgorFtERG19X+bzWuffTa86lWwaZOzFUqS1GpN\nnyGIiGXAaRwaHXBKRKwCdqSUfgRcDlwdEUPAZrKL/0uBq2fT0KOPdtihJEntMpNLBucBXyObgyCR\nzTkA8EngLSmla2tzDryf7FLBt4FXpJQemU1Dly41EEiS1C5NB4KU0teZ4lJDSulK4MqZNmoiS5fC\ntm2tfEVJkjQmN/cyuOkmuP12JyaSJKkdchMItm2DffucmEiSpHbITSCo99BDnW6BJEnFkstAcMIJ\nnW6BJEnFkpuZCo8+epDdu3s59dQy1arTFUuSdCRj0xg3M3VxZPcemr8iog8Y+qu/GuId7+jjvvvg\n5JM73SpJkua/uqmL+1NKw5Ptm5tLBsuXZz+bCDuSJGmaDASSJCk/gWD//uzn617nXASSJLVabgLB\nBz+Y/RwZcS4CSZJaLTeBYMeO8evORSBJUuvkJhAce+z4decikCSpdXITCC67DBYvht5eWLsWqtVO\nt0iSpOLIzcREK1bA858P558PGzZ0ujWSJBVLbs4QbN8O99wDn/mMowwkSWq13ASCd78bHn0UHn/c\nUQaSJLVabgLBtm3j1x1lIElS6+SmhmDXrkGgFygDZUcZSJJ0BIW+udFXvjLEW9/axwMPwJo12SiD\nUqnTrZMkaf4q5M2NVqyASy6BBQvgX//VMCBJUivlJhBAFgr27csKCyVJUuvkJhBs3w4f+EC2/LKX\nOexQkqRWyk0gePe74c47s+Vbb3XYoSRJrZSbQOCwQ0mS2ic3gcCbG0mS1D65CQSXXQYvfGG2fNpp\n3txIkqRWyk0gWLEim7L4Gc+AX/1Vhx1KktRKuQkEACMjsHs3/NEfeYMjSZJaKVeBYGAA9uyBH//Y\nGxxJktRKuQoEjSMLHGkgSVJr5CoQNI4scKSBJEmtkZu7HQ4ODrJsWS+9vWV27y6zerUjDSRJmkih\n73Y4NDREX18f73sfXHMN3Hdfp1smSdL8Vsi7HUI2yuCzn4X773eUgSRJrZSrQDAwkJ0ZSMlRBpIk\ntVKuAoGjDCRJao9cBQJHGUiS1B65CgTVKvT1Zctnn+0oA0mSWiVXgaBUgi9/OVv+gz/wfgaSJLVK\nrgIBwN692c/16x1pIElSq+QuELzuddnPbdscaSBJUqvkLhA40kCSpNbLXSBwpIEkSa2Xu0BQrcIx\nx8DRR8PatY40kCSpFXIXCFKCnh44cKDTLZEkqThyFwgGBrJ7Guzda1GhJEmtkrtAYFGhJEmt19Pp\nBkzX4OAgvb299PSUgfJT2y0qlCRpvEqlQqVSYXR0dNrHREqpjU2avYjoA4aGhobo6+vj4YfhZS+D\nO++E886Df/gHZyyUJGkiw8PD9Pf3A/SnlIYn2zd3lwxKJfjkJ7Plq64yDEiS1Aq5CwT1XvUqpy+W\nJKkVchkIfuM3sp9btzrSQJKkVshlIGg8I+BIA0mSZieXgcDpiyVJaq3cDDusV63CqadCBJxzjtMX\nS5I0W7k8Q5ASLFzo9MWSJLVKLgPBwADs3AlPPGFRoSRJrZDLQOD0xZIktVYuA4FFhZIktVYuA0G1\nCqefni2vWWNRoSRJs5XLQFAqwaWXZstbtmQ1BM5WKEnSzOUyEAD86Z9mP++/38JCSZJmK7eBYOfO\n8esWFkqSNHO5DQQnnjh+3cJCSZJmLreB4AtfgKOOghUrYO1aCwslSZqN3AaCsdkKDx7sdEskScq/\n3NzLYHBwkN7eXsrlMuVymYEB2LMne4wVFW7a1OlWSpLUeZVKhUqlwujo6LSPiZRSG5s0exHRBwwN\nDQ3R19f31PZTT4Uf/vDQfqecAvfcM/ftkyRpvhoeHqa/vx+gP6U0PNm+ub1k4GyFkiS1Tm4DQbWa\njTTo6bGoUJKk2cptICiVYHAQlizJagdKpU63SJKk/MptIBgZgauugscegxe+0KmLJUmajdwGgoEB\n+MEPsuVvfMOpiyVJmo3cBoLGqYqduliSpJnLbSBwlIEkSa2T20BQrcKaNdny6ac7ykCSpNnIbSAo\nleDzn4cFC2D79qyGwMJCSZJmJreBALLCwgMHYMeOQ9MXS5Kk5uU6EFhYKElSa+Q6EFhYKElSa+Q6\nEFSrsHIlLF7s9MWSJM1GrgNBStm9DA4c6HRLJEnKt1wHgoEB2LIF9u+3qFCSpNnIdSCwqFCSpNbI\ndSCwqFCSpNbIdSCoVmHVqmx51SqLCiVJmqlcB4JSCa6+OlseGXG2QkmSZirXgQDg4ouzn1u3Wlgo\nSdJM5T4QjIyMX7ewUJKk5uU+EFhYKEnS7PV0ugHTNTg4SG9vL+VymXK5/NT2ahVOOy2bpMjCQkmS\noFKpUKlUGB0dnfYxkVJqY5NmLyL6gKGhoSH6+voOe35kBJ7/fNi9G/r6skBQKs19OyVJmm+Gh4fp\n7+8H6E8pDU+2b+4vGQwMZLc/3r3bokJJkmYq94HA2QolSZq93AcCiwolSZq93AeCahWe97xs+ad/\n2qJCSZJmIveBoFSCD3wgW96yxdkKJUmaidwHAoAPfSj7+aMfWVgoSdJMFCIQ7Ngxft3CQkmSmlOI\nQHDSSePXLSyUJKk5hQgEn/88LFgAK1bA2rUWFkqS1KxCBIKUYOFCOHCg0y2RJCmfChEIBgbgySdh\ndNSiQkmSZqIQgcDZCiVJmp1CBAJnK5QkaXYKEQiq1WykwYIFFhVKkjQThQgEFhVKkjQ7hQgEAwNw\n773ZskWFkiQ1rxCBwKJCSZJmpxCBwKJCSZJmpxCBoFqFCy7Ils8806JCSZKaVYhAUCrBF74AEfDI\nI94CWZKkZhUiEAC89rXZaIPt2y0slCSpWYUJBBYWSpI0c4UJBBYWSpI0c4UJBNUqrFwJixc7W6Ek\nSc0qTCAYm61w//5Ot0SSpPwpTCAYGIAHHsimL7aoUJKk5hQmEFhUKEnSzBUmEFhUKEnSzPV0ugHT\nNTg4SG9vL+VymXK5fNjz1Sq8/OXwne9ktQT79mWTE5VKHWisJEkdVKlUqFQqjI6OTvuYSCm1sUmz\nFxF9wNDQ0BB9fX2T7rtmDdxyy6H1tWth06b2tk+SpPlqeHiY/v5+gP6U0vBk+xbmkgEcPl2xdQSS\nJE1PoQKBdQSSJM1MoQJBtQpPexosX+7kRJIkNaNQgWBscqIDBzrdEkmS8qVQgWBgAHbsgN27nZxI\nkqRmFCoQODmRJEkzU6hAYFGhJEkzU6hAUK3CmWdmy+efb1GhJEnTVahAUCrBZZdlyw8+mNUQNM5N\nIEmSDleoQABw6aXZzwcesLBQkqTpKlwg2L59/LqFhZIkTa1wgeDEE8evW1goSdLUChcINmyAiOzx\ntKfBVVd1ukWSJM1/hQsE69dnMxamBLt2wdve1ukWSZI0/xUuEDg5kSRJzStcIHByIkmSmle4QFCt\nwsknZzUE3vFQkqTpKVwgSAkWL85+etdDSZKmp3CBYGAAvv/9bPmWW5yYSJKk6ShcILCoUJKk5hUu\nEFhUKElS8woXCKpVWL06W+7pgX37vMGRJElTKVwgKJVg0aJsef9+2LzZOgJJkqZSuEAA1hFIktSs\nQgYC6wgkSWpOIQPBhg2HLht4gyNJkqZWyECwfj3s3Zste4MjSZKmVshAYA2BJEnNKWQgsIZAkqTm\nFDIQVKtwzjnZ8sKFzkUgSdJUChkISiVYtixb3rfPuQgkSZpKIQMBwMjI+HXrCCRJOrLCBgLrCCRJ\nmr7CBoING2DBAohwLgJJkqZS2ECwfj0cOAApOReBJElTKWwgcC4CSZKmr7CBwBoCSZKmr7CBoFqF\n00/Plhctci4CSZImU9hAUD8Xwd69zkUgSdJkChsIAHbuHL9uHYEkSRMrdCA46aTx69YRSJI0sZ5O\nN2C6BgcH6e3tpVwuUy6Xp3XMhg2H7mmwfLlzEUiSukOlUqFSqTA6OjrtYyKl1MYmzV5E9AFDQ0ND\n9PX1NXXshRfCzTcfWl+7FjZtam37JEmar4aHh+nv7wfoTykNT7ZvoS8ZOBeBJEnTU+hA4FwEkiRN\nT6EDwYYNsHhxtuz9DCRJOrJCB4L162HPnmzZ+xlIknRkhQ4E1hBIkjQ9hQ4E1hBIkjQ9hQ4E1Sqs\nXp0t9/R4PwNJko6k0IGgVMpubASwf7/3M5Ak6UgKHQjAOgJJkqaj8IHAOgJJkqZW+ECwYcOhywbO\nRSBJ0sQKHwjWr4e9e7Nl5yKQJGlihQ8E1hBIkjS1wgeCxpqBRx5x6KEkSY0KHwiq1ax2YMyuXQ49\nlCSpUeEDQakExx03fpuXDSRJGq/wgQAceihJ0lS6IhBs2JBNXRzh0ENJkibSFYFg/fps6uKUHHoo\nSdJEuiIQOPRQkqTJdUUgsIZAkqTJdUUgqFbhrLOy5UWLvA2yJEmNuiIQlEqwfHm2vHevt0GWJKlR\nVwQCgO3bx69bRyBJ0iFdEwiOOWbydUmSulnXBIKIydclSepmXRMItm2bfF2SpG7WNYHASwaSJB1Z\n1wQCLxlIknRkXRMIvGQgSdKRdU0gaJyd8JFHnJxIkqQxXRMIqtXsTodjdu1yciJJksZ0TSAoleC4\n48Zvc3IiSZIyXRMIwJEGkiQdSVcFAkcaSJI0sa4KBI40kCRpYl0VCBxpIEnSxLoqEDjSQJKkiXVV\nIHCkgSRJE+uqQACONJAkaSJdFwgcaSBJ0uG6LhA40kCSpMN1XSBwpIEkSYfrukBQrcLy5YfWHWkg\nSVIXBoJSCVasGL/tgQc60xZJkuaLrgsEADt3jl/fsaMz7ZAkab7oykDQeIagcV2SpG7TlYGgVJp8\nXZKkbtOVgcC5CCRJGq8rA4FzEUiSNF5XBgLnIpAkabyuDATe9VCSpPG6MhCUSvDMZ47f5lwEkqRu\n1pWBAJyLQJKkel0bCJyLQJKkQ7o2EJx00vj1HTssLJQkda+uDQQWFkqSdEjXBgILCyVJOqRrAwFY\nWChJ0piuDgSNhYR791pHIEnqTl0dCBoLC/fssY5AktSdujoQVKuwaNH4bdYRSJK6UVcHglIJFi8e\nv806AklSN+pYIIiIV0fE3RHxvYh4a6fa4QRFkiR1KBBExALgI8BLgX7gdyLimZMe1CZOUCRJUufO\nEJwP/HtKaWtK6THgH4Cf6URDqlVYuvTQ+q5d8OpXd6IlkiR1TqcCwbOALXXrW4ATO9GQUgkOHBi/\n7Y47OtESSZI6p+lAEBEviojrI2JLRByMiHUT7PP2iLg3InZHxC0Rsbo1zW2PlCZflySp6GZyhmAZ\n8G3gYuCwP50R8Xqy+oBLgXOB24EbIuLYut0eBOqv3p9Y29YRjUMPG9clSSq6pgNBSumfUkq/n1L6\nIhAT7DIIXJVS+lRK6W5gPfAE8Ja6fTYDPxkRJ0TEcuBngRuab35rHHPM5OuSJBVdS2sIImIh2aiB\nr45tSykl4EZgTd22A8BvA/8CDAOXpZQa7iwwdxxpIEnqdj0tfr1jgQXASMP2EeCM+g0ppb8H/n66\nLzw4OEhvb++4beVymXK5PLOW1qlW4ZRT4PHHs/WxkQabN8/6pSVJmhOVSoVKpTJu2+jo6LSPjzSL\nCrqIOAj8t5TS9bX1E8hGDKxJKX2zbr8PAy9OKa2Z+JUmfY8+YGhoaIi+vr4Zt3UqS5Zk9zIYs3gx\nPPlk295OkqS2Gx4epr+/H6A/pTQ82b6tHna4DTgArGzYvhLY2uL3aivvfChJ6iYtDQQppX3AEHDR\n2LaIiNr6v7XyvVpt1arx6yl550NJUvdouoYgIpYBp3FohMEpEbEK2JFS+hFwOXB1RAyRjSYYBJYC\nV7ekxW2ycSM8+9nZmYEx3vlQktQtZlJUeB7wNbI5CBLZnAMAnwTeklK6tjbnwPvJLhV8G3hFSumR\nFrS3bcbufNgYCB5+OHtOkqQiazoQpJS+zhSXGlJKVwJXzrRRnbJiRTbCYMyBA9llg02bOtcmSZLm\nQsdufzwfNc5HAF42kCR1BwNBnWoVjmrokW3bOtMWSZLmkoGgTqkECxeO37Z/f2faIknSXDIQTMH5\nCCRJ3SA3gWBwcJB169YdNi1jq000H8GrX93Wt5QkqaUqlQrr1q1jcHBw2sfMauriuTBXUxePefhh\nOP74LAgcagNs3erwQ0lSvnRy6uLcK5Vg0aLx2zxLIEkqOgPBBBovGwDcccfct0OSpLliIJjAxo3Z\nZYJ6FhdKkorMQDCBUglWrx6/zcsGkqQiMxAcwcaNh2+7/fa5b4ckSXPBQHAEpZKXDSRJ3cNAMInG\n0QYAp55qKJAkFY+BYBITjTZ47DFrCSRJxWMgmMREow0Abr3VswSSpGIxEExiotEG4IgDSVLx9HS6\nAdM1ODhIb28v5XKZcrk8Z++7cWNWN/DYY+O3j50lcDpjSdJ8U6lUqFQqjI6OTvsY72UwDQ8/DCtX\nHr59+XK45x5DgSRpfvJeBi1WKsHixYdvf+wxRx1IkorBQDBNE404gCwUnHKKoUCSlG8GgmnauDG7\nRDCRxx+HE06A7353btskSVKrGAimqVTK6gWOFAoOHoSzz4abbprbds1WpVLpdBMKyX5tH/u2PezX\n9shTvxoImjAWCo6apNde8pLs+b6+fFxGyNMva57Yr+1j37aH/doeeepXA0GTSiW4447JQ0FKcNtt\n2ciEiOzRjpAwMgIXXpgVNl54YfsCyMgInH9+Vlh51FGwZAlccEE+As98Nlf//SRpOgwEM/CTPwkP\nPQQveMH0j5koJMz2cfzxcPPN8MMfZj9n8tpjszFO9T7f+lZ2c6eUYM8e2Ly5tZ+laI8j9etzn5uF\nqun891u+HD7xiUP7jwXLRYta395ly8bXwNSHlfPPzwLgSSdBT8+hx7Of3XyQ+fd/z95rqvYsWJC9\nx2R929OT9VFfH5x8cra8ZElzgXUs7E513HT3m+i4Cy/M+q7xv+N8PYvYiaCa93Cc9/aPcR6CWbrp\npuwyQX6tA67vdCMKyH5tH/u2PezX9uh0vw4D05uHIA8zFS4BuOuuuzrdjgktXw7XXgtvfjM8+WSn\nWzMTo2S/MGot+7V97Nv2sF/bo9P9+tTfziVT7ZmHMwRvBK7pdDskScqxX04pfXayHfIQCI4BXgHc\nB+TyO7gkSR2yBPgJ4IaU0vbJdpz3gUCSJLWfowwkSZKBQJIkGQgkSRIGAkmShIFAkiSRg0AQEW+P\niHsjYndE3BIRqzvdpvksIt4bEZsj4tGIGImIz0fE8ybY7/0R8WBEPBERX4mI0xqeXxwRH42IbRGx\nKyKui4jS3H2S+S0i3hMRByPi8obt9muTIuJZEfHpWp88ERG312Yord/Hfm1SRBwVEf87In5Y67f/\niIjfnWA/+3YSEfGiiLg+IrbU/p9fN8E+s+7DiHhmRFwTEaMRsTMi/iYilrX789Wb14EgIl4PfAS4\nFDgXuB24ISKO7WjD5rcXAX8JXAC8HFgIfDkijh7bISJ+B3gH8GvA+cDjZP26qO51/gx4FTAAvBh4\nFvC5ufgA810tlP4a2e9j/Xb7tUkR8QzgZmAP2XwjZwG/Deys28d+nZn3AG8DLgbOBC4BLomId4zt\nYN9OyzLg22T9eNg4/Rb24WfJfv8vqu37YuCqVn6QKaWU5u0DuAX487r1AB4ALul02/LyAI4FDgIX\n1m17EBisW386sBv4pbr1PcAv1u1zRu11zu/0Z+pwfy4Hvgf8F+BrwOX266z684+Br0+xj/06s77d\nCHysYdt1wKfs2xn36UFgXcO2WfchWRA4CJxbt88rgP3A8XP1+ebtGYKIWEh2R4avjm1LWS/dCKzp\nVLty6BlkqXYHQEQ8Fzie8f36KPBNDvXreWT3uajf53vA/dj3HwU2ppT+uX6j/TpjPw/cGhHX1i5x\nDUfE/xx70n6dlX8DLoqI0wEiYhWwFvhSbd2+naUW9uFPAztTSrfVvfyNZP92X9Cu9jeazzc3OhZY\nAIw0bB8hS1eaQkQE2amqTSmlO2ubjyf7JZuoX4+vLa8E9tZ+sY+0T9eJiDcALyD7H7yR/TozpwC/\nTnZp8IMcOl84AAAC0klEQVRkp1z/IiL2pJQ+jf06G39M9u307og4QHaJ+H0ppf9be96+nb1W9eHx\nwLibJqeUDkTEDuawn+dzINDsXQk8n+xbgWYhIk4iC1cvTynt63R7CuQoYHNK6fdq67dHxNnAeuDT\nnWtWIbweeCPwBuBOsjD75xHxYC1sSePM20sGwDbgAFm6qrcS2Dr3zcmXiPgr4JXAS1NKD9U9tZWs\nFmOyft0KLIqIp0+yT7fpB44DhiNiX0TsA14C/K+I2EuW9u3X5j1E3f1Za+4CnlNb9vd15v4E+OOU\n0t+llL6bUroGuAJ4b+15+3b2WtWHW4HGUQcLgBXMYT/P20BQ+xY2RFZxCTx1CvwismtjOoJaGPgF\n4GUppfvrn0sp3Uv2C1bfr08nu0411q9DZMUs9fucQfaP9Dfa2vj560bgp8i+Za2qPW4FPgOsSin9\nEPt1Jm7m8EuAZwD/Cf6+ztJSsi9V9Q5S+3ffvp29FvbhN4BnRMS5dS9/EVnY+Ga72n+YTldtTlHR\n+UvAE8CbyYbNXAVsB47rdNvm64PsMsFOsuGHK+seS+r2uaTWjz9P9kfuC8APgEUNr3Mv8FKyb8c3\nA//a6c83nx4cPsrAfm2+D88jq8B+L3Aq2SnuXcAb7NdZ9+0nyArXXgmcDPwi2XXqD9m3TfXjMrIv\nAC8gC1TvrK0/u5V9SFbseSuwmuwy7/eAT8/pZ+10Z0/jP8bFwH1kwzi+AZzX6TbN50ftF/bABI83\nN+z3B2TDZZ4AbgBOa3h+Mdl8Bttq/0D/HVDq9OebTw/gn+sDgf064358JXBHrc++C7xlgn3s1+b7\ndRlwee0P0eO1P1J/CPTYt03140uO8O/q37ayD8lGhH0GGCX7UvcxYOlcftaoNUSSJHWxeVtDIEmS\n5o6BQJIkGQgkSZKBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmSBPx/EO8ZUP0A\nyqEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x261013edb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(error_valid)),np.array(error_valid),marker='.')\n",
    "plt.suptitle('lambda = 0.05')\n",
    "plt.axis('tight')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 0.297474047707 0.29742780134 0:02:36.084479\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1 # Learning rate\n",
    "lambdas = 0.001 # regularization factor \n",
    "x = T.dmatrix('x')\n",
    "y = T.lvector('y')\n",
    "w = theano.shared(np.random.randn(train_set[0].shape[1],len(np.unique(train_set[1]))),name='w',borrow=True)\n",
    "b = theano.shared(value=np.zeros((len(np.unique(train_set[1])),),dtype=theano.config.floatX),name='b',borrow=True)\n",
    "p_y_given_x = T.nnet.softmax(T.dot(x, w) + b)   # Probability that target belongs to class i\n",
    "prediction = T.argmax(p_y_given_x, axis=1)      # The prediction of the model (class whose probability is maximal)\n",
    "loss = -T.mean(T.log(p_y_given_x)[T.arange(y.shape[0]), y])  # Loss function\n",
    "cost = loss.mean() + lambdas * (w ** 2).sum()      # The cost to minimize\n",
    "gw = T.grad(cost=cost, wrt=w)\n",
    "gb = T.grad(cost=cost, wrt=b)\n",
    "train = theano.function(inputs=[x,y], outputs=[prediction, loss],\n",
    "          updates=((w, w - eta * gw), (b, b - eta * gb)),name='train')\n",
    "validate = theano.function(inputs=[x,y],outputs=[prediction, loss],name='validate')\n",
    "test = theano.function(inputs=[x,y],outputs=[prediction, loss],name='test')\n",
    "predict = theano.function(inputs=[x], outputs=prediction, name='predict')\n",
    "# Train\n",
    "n_epochs = 100\n",
    "batch_size = 256    # size of the minibatch\n",
    "n_train_batches = train_set[0].shape[0] // batch_size\n",
    "n_valid_batches = valid_set[0].shape[0] // batch_size\n",
    "n_test_batches = test_set[0].shape[0] // batch_size\n",
    "error_train = []   \n",
    "error_valid = []\n",
    "error_new, error_old, i = 1,0,0\n",
    "time1=datetime.datetime.now()\n",
    "while abs(error_old - error_new) > 1e-4: ## early stop\n",
    "    error_old = error_new\n",
    "    order = np.random.permutation(train_set[0].shape[0])\n",
    "    permutex = train_set[0][order]\n",
    "    permutey = train_set[1][order]\n",
    "    error_valid_int = []\n",
    "    for index in range(n_train_batches):\n",
    "        # Now for the update we only use one mini-batch at a time\n",
    "        pred, err = train(permutex[index * batch_size: (index + 1) * batch_size], \\\n",
    "                          permutey[index * batch_size: (index + 1) * batch_size])\n",
    "        error_train.append(err)  # save the train error for this batch\n",
    "        errores = []             \n",
    "        # Now we check the performance on the validation set, every 2 batches.\n",
    "        if (index%2 == 0):\n",
    "            for j in range(n_valid_batches):\n",
    "                pred_val, err_val = validate(valid_set[0][j * batch_size: (j + 1) * batch_size], \\\n",
    "                              valid_set[1][j * batch_size: (j + 1) * batch_size])\n",
    "                errores.append(err_val)\n",
    "            # We get the validation error as the average over batches\n",
    "            this_error = np.mean(errores)\n",
    "            error_valid.append(this_error)\n",
    "            error_valid_int.append(this_error)           \n",
    "    error_new = np.mean(error_valid_int)\n",
    "    i=i+1\n",
    "    if(i==n_epochs):break ## compulsory stop\n",
    "time2=datetime.datetime.now()\n",
    "print(i,error_old,error_new,time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAF9CAYAAAB7x3ACAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2610254dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(error_valid)),np.array(error_valid),marker='.')\n",
    "plt.suptitle('lambda = 0.001')\n",
    "plt.axis('tight')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I stop the training process when the difference in average validate error across batches is smaller than 1e-4. For example, in the case of $\\lambda=0.01$, I stop training after 13 rounds of mini-batch gradient descent, within each round there are [50000/256] updates for the parameter $w$ and $b$. Below is a summary table of results under different choices of $\\lambda$.\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Lambda</td><td>Average Loss</td><td>Rounds of updates</td><td>Time Needed</td></tr><tr><td>0.05</td><td>0.7239</td><td>11</td><td>00:36</td></tr><tr><td>0.01</td><td>0.4413</td><td>14</td><td>00:48</td></tr><tr><td>0.005</td><td>0.3768</td><td>15</td><td>00:50</td></tr><tr><td>0.001</td><td>0.2975</td><td>47</td><td>02:36</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "temp = [['Lambda','Average Loss','Rounds of updates','Time Needed'],\n",
    "         [0.05,0.7239,11,'00:36'],\n",
    "         [0.01,0.4413,14,'00:48'],\n",
    "         [0.005,0.3768,15,'00:50'],\n",
    "         [0.001,0.2975,47,'02:36'],\n",
    "         ]\n",
    "\n",
    "display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in temp)\n",
    "        )\n",
    " ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error =  8.28\n"
     ]
    }
   ],
   "source": [
    "aa = T.dvector('aa')\n",
    "bb = T.dvector('bb')\n",
    "cc = T.mean(T.neq(aa, bb))\n",
    "f_err = theano.function([aa, bb], cc)\n",
    "print('Test error = ',100.*f_err(test_set[1],predict(test_set[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to choose $\\lambda=0.001$, it reaches the minimun average loss and consumes a reasonable amount of time, the test error is 8.28%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. The Multilayer Perceptron (with one hidden layer)\n",
    "The multilayer perceptron can be understood as a logistic regression classifier in which the input is first transformed using a learnt non-linear transformation. The non-linear transformation is usually chosen to be either the logistic function or the $\\tanh$ function, and its purpose is to project the data into a space where it becomes linealry separable The output of this so-called hidden layer is then passed to the logistic regression graph that we have constructed in the first problem. In matrix notation:\n",
    "\n",
    "$$G(b^{(2)}+W^{(2)}(s(b^{(1)}W^{(1)}x)))$$\n",
    "\n",
    "with bias vectors $b^{(1)}$, $b^{(2)}$; weight matrices $W^{(1)}$, $W^{(2)}$ and activation functions $G$ and $s$. Here is a diagram:\n",
    "\n",
    "![](http://deeplearning.net/tutorial/_images/mlp.png){:height=300 width=300}\n",
    "\n",
    "### Part A\n",
    "\n",
    "Using a similar architecture as in the first part and the same MNIST dataset, built a Theano graph for the multilayer perceptron, using the $\\tanh$ function as the non-linearity. Use $\\eta = 0.1$ and $\\lambda = 0.001$. Experiment with the batch size (use 20, 50, and 100 examples) and the number of units in your hidden layer (use 50, 100, and 200 units). For what combination of these parameters do you obtain the smallest value of the validation loss function after 50 epochs?\n",
    "\n",
    "### Part B\n",
    "\n",
    "Stop the trainning at a convenient validation loss and use the trained classifier to predict for the test set. How much better is your test error as compared to the logistic regression classifier?\n",
    "\n",
    "*Hint 1:* The initialization of the weights matrix for the hidden layer must assure that the units (neurons) of the perceptron operate in a regime where information gets propagated. For the $\\tanh$ function, it is advisable to initialize with the interval $[-\\sqrt{\\frac{6}{fan_{in}+fan_{out}}},\\sqrt{\\frac{6}{fan_{in}+fan_{out}}}]$, where $fan_{in}$ is the number of units in the $(i-1)$-th layer, and $fan_{out}$ is the number of units in the i-th layer.\n",
    "\n",
    "*Hint 2:* You should feel free to get inspiration from [these tutorials](http://deeplearning.net/tutorial/mlp.html). However, we expect you to write your own code, inspired by the architecture shown in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 20 n_hidden= 50 error= 0.136652355855 time= 1:09:04.798325\n",
      "batch_size= 20 n_hidden= 100 error= 0.128706196052 time= 1:28:31.390745\n",
      "batch_size= 20 n_hidden= 200 error= 0.128080647713 time= 1:59:14.903516\n",
      "batch_size= 50 n_hidden= 50 error= 0.132305761701 time= 0:19:16.868359\n",
      "batch_size= 50 n_hidden= 100 error= 0.124063054504 time= 0:27:26.865372\n",
      "batch_size= 50 n_hidden= 200 error= 0.12441433617 time= 0:39:48.138210\n",
      "batch_size= 100 n_hidden= 50 error= 0.136850608483 time= 0:08:16.656609\n",
      "batch_size= 100 n_hidden= 100 error= 0.12608560783 time= 0:12:23.679375\n",
      "batch_size= 100 n_hidden= 200 error= 0.125196422871 time= 0:20:42.835217\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [20,50,100]:\n",
    "    for n_hidden in [50,100,200]:\n",
    "        eta = 0.1 # Learning rate\n",
    "        lambdas = 0.001 # regularization factor \n",
    "        x = T.dmatrix('x')\n",
    "        y = T.lvector('y')\n",
    "        n_in = train_set[0].shape[1]\n",
    "        n_out = len(np.unique(train_set[1]))\n",
    "        w1 = theano.shared(np.random.uniform(low=-np.sqrt(6. / (n_in + n_hidden)),\n",
    "                    high=np.sqrt(6. / (n_in + n_hidden)),size=(n_in, n_hidden)),name='w',borrow=True)\n",
    "        w2 = theano.shared(np.random.randn(n_hidden,n_out),name='w',borrow=True)\n",
    "        b1 = theano.shared(value=np.zeros(n_hidden, dtype=theano.config.floatX),name='b',borrow=True)\n",
    "        b2 = theano.shared(value=np.zeros(n_out, dtype=theano.config.floatX),name='b',borrow=True)\n",
    "\n",
    "        h = T.tanh(T.dot(x, w1) + b1)\n",
    "        p_y_given_h = T.nnet.softmax(T.dot(h, w2) + b2)  \n",
    "        prediction = T.argmax(p_y_given_h, axis=1)      \n",
    "        loss = -T.mean(T.log(p_y_given_h)[T.arange(y.shape[0]), y])  \n",
    "        cost = loss.mean() + lambdas * ((w1**2).sum() + (w2**2).sum())  \n",
    "        gw1 = T.grad(cost=cost, wrt=w1)\n",
    "        gw2 = T.grad(cost=cost, wrt=w2)\n",
    "        gb1 = T.grad(cost=cost, wrt=b1)\n",
    "        gb2 = T.grad(cost=cost, wrt=b2)\n",
    "\n",
    "        train = theano.function(inputs=[x,y], outputs=[prediction, loss],\n",
    "                updates=((w1, w1 - eta * gw1), (w2, w2 - eta * gw2),\n",
    "                (b1, b1 - eta * gb1), (b2, b2 - eta * gb2)),name='train')\n",
    "        validate = theano.function(inputs=[x,y],outputs=[prediction, loss],name='validate')\n",
    "        test = theano.function(inputs=[x,y],outputs=[prediction, loss],name='test')\n",
    "        predict = theano.function(inputs=[x], outputs=prediction, name='predict')\n",
    "        # Train\n",
    "        n_train_batches = train_set[0].shape[0] // batch_size\n",
    "        n_valid_batches = valid_set[0].shape[0] // batch_size\n",
    "        n_test_batches = test_set[0].shape[0] // batch_size\n",
    "        error_train = []   \n",
    "        error_valid = []\n",
    "        error_new, error_old, i = 1,0,0\n",
    "        i=0\n",
    "        time1=datetime.datetime.now()\n",
    "        while i<50: \n",
    "            error_old = error_new\n",
    "            order = np.random.permutation(train_set[0].shape[0])\n",
    "            permutex = train_set[0][order]\n",
    "            permutey = train_set[1][order]\n",
    "            error_valid_int = []\n",
    "            for index in range(n_train_batches):\n",
    "                pred, err = train(permutex[index * batch_size: (index + 1) * batch_size], \\\n",
    "                          permutey[index * batch_size: (index + 1) * batch_size])\n",
    "                error_train.append(err)  # save the train error for this batch             \n",
    "                if (index%2 == 0):\n",
    "                    errores = []\n",
    "                    for j in range(n_valid_batches):\n",
    "                        pred_val, err_val = validate(valid_set[0][j * batch_size: (j + 1) * batch_size], \\\n",
    "                              valid_set[1][j * batch_size: (j + 1) * batch_size])\n",
    "                        errores.append(err_val)\n",
    "                this_error = np.mean(errores)\n",
    "                error_valid.append(this_error)\n",
    "                error_valid_int.append(this_error)            \n",
    "            error_new = np.mean(error_valid_int)\n",
    "            i=i+1\n",
    "        time2=datetime.datetime.now()\n",
    "        print('batch_size=',batch_size,'n_hidden=',n_hidden,'error=',error_new,'time=',time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 100 n_hidden= 200 error= 0.125550669009 time= 0:25:55.166655\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_hidden = 200\n",
    "eta = 0.1 # Learning rate\n",
    "lambdas = 0.001 # regularization factor \n",
    "x = T.dmatrix('x')\n",
    "y = T.lvector('y')\n",
    "n_in = train_set[0].shape[1]\n",
    "n_out = len(np.unique(train_set[1]))\n",
    "w1 = theano.shared(np.random.uniform(low=-np.sqrt(6. / (n_in + n_hidden)),\n",
    "     high=np.sqrt(6. / (n_in + n_hidden)),size=(n_in, n_hidden)),name='w',borrow=True)\n",
    "w2 = theano.shared(np.random.randn(n_hidden,n_out),name='w',borrow=True)\n",
    "b1 = theano.shared(value=np.zeros(n_hidden, dtype=theano.config.floatX),name='b',borrow=True)\n",
    "b2 = theano.shared(value=np.zeros(n_out, dtype=theano.config.floatX),name='b',borrow=True)\n",
    "\n",
    "h = T.tanh(T.dot(x, w1) + b1)\n",
    "p_y_given_h = T.nnet.softmax(T.dot(h, w2) + b2)  \n",
    "prediction = T.argmax(p_y_given_h, axis=1)      \n",
    "loss = -T.mean(T.log(p_y_given_h)[T.arange(y.shape[0]), y])  \n",
    "cost = loss.mean() + lambdas * ((w1**2).sum() + (w2**2).sum())  \n",
    "gw1 = T.grad(cost=cost, wrt=w1)\n",
    "gw2 = T.grad(cost=cost, wrt=w2)\n",
    "gb1 = T.grad(cost=cost, wrt=b1)\n",
    "gb2 = T.grad(cost=cost, wrt=b2)\n",
    "train = theano.function(inputs=[x,y], outputs=[prediction, loss],\n",
    "        updates=((w1, w1 - eta * gw1), (w2, w2 - eta * gw2),\n",
    "        (b1, b1 - eta * gb1), (b2, b2 - eta * gb2)),name='train')\n",
    "validate = theano.function(inputs=[x,y],outputs=[prediction, loss],name='validate')\n",
    "test = theano.function(inputs=[x,y],outputs=[prediction, loss],name='test')\n",
    "predict = theano.function(inputs=[x], outputs=prediction, name='predict')\n",
    "# Train\n",
    "n_train_batches = train_set[0].shape[0] // batch_size\n",
    "n_valid_batches = valid_set[0].shape[0] // batch_size\n",
    "n_test_batches = test_set[0].shape[0] // batch_size\n",
    "error_train = []   \n",
    "error_valid = []\n",
    "error_new, error_old, i = 1,0,0\n",
    "i=0\n",
    "time1=datetime.datetime.now()\n",
    "while i<50: \n",
    "    error_old = error_new\n",
    "    order = np.random.permutation(train_set[0].shape[0])\n",
    "    permutex = train_set[0][order]\n",
    "    permutey = train_set[1][order]\n",
    "    error_valid_int = []\n",
    "    for index in range(n_train_batches):\n",
    "        pred, err = train(permutex[index * batch_size: (index + 1) * batch_size], \\\n",
    "                    permutey[index * batch_size: (index + 1) * batch_size])\n",
    "        error_train.append(err)  # save the train error for this batch             \n",
    "        if (index%2 == 0):\n",
    "            errores = []\n",
    "            for j in range(n_valid_batches):\n",
    "                pred_val, err_val = validate(valid_set[0][j * batch_size: (j + 1) * batch_size], \\\n",
    "                        valid_set[1][j * batch_size: (j + 1) * batch_size])\n",
    "                errores.append(err_val)\n",
    "        this_error = np.mean(errores)\n",
    "        error_valid.append(this_error)\n",
    "        error_valid_int.append(this_error)            \n",
    "    error_new = np.mean(error_valid_int)\n",
    "    i=i+1\n",
    "time2=datetime.datetime.now()\n",
    "print('batch_size=',batch_size,'n_hidden=',n_hidden,'error=',error_new,'time=',time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error =  3.29\n"
     ]
    }
   ],
   "source": [
    "print('Test error = ',100.*f_err(test_set[1],predict(test_set[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Test error reduces from 8.28% to 3.29%"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
