library(ggplot2)


#### Experiment 2
# Cuda
cuda_loss = c(4.1864476875070498, 1.865434858882016, 1.3818578036667259, 1.2421049187369453, 1.2219228250183762, 1.1873860242316081, 1.1846561050447364, 1.1710844644701346, 1.1613778645745194, 1.1493520467384983, 1.1486139531994601, 1.1486329878652393, 1.1475968786482387, 1.1430827979061242, 1.1375225084927636, 1.134093707839813, 1.1387619425528999, 1.1353218764150035, 1.1320594642265562, 1.1284367749675048, 1.1269697379726504, 1.1305691111583789, 1.1270616333844874, 1.125361624011326, 1.1253850482175052, 1.1243962485015861, 1.1191883372933205, 1.1238793118627746, 1.1193141058414389, 1.1171560023823144, 1.1182097850154187, 1.121804613509872, 1.1199013876335144, 1.1185683033323097, 1.11573777934897, 1.1236124903395484, 1.1206623345307904, 1.1186482728350902, 1.1164625420447942, 1.1176355209060467, 1.1155702649067138, 1.1163384416640567, 1.1138471192287678, 1.1146196820818564, 1.1126506529201059, 1.1180572273488592)
cuda_valLoss = c(2.0072012491365161, 1.3308836910046791, 1.1898811319972329, 1.1591923007800271, 1.1440527465374983, 1.1353673947055394, 1.1289888098861194, 1.1249343452515015, 1.1217366368113757, 1.119602660290955, 1.1173755876980003, 1.115369172348325, 1.1127866855196047, 1.1114358811086009, 1.1102419876317096, 1.1093661824310079, 1.1086304077492937, 1.1080767201068482, 1.1072314161641927, 1.1065888436355256, 1.1064304149340711, 1.1061709708013765, 1.1057600138026631, 1.1053760534462302, 1.1051187629984096, 1.1049061889609657, 1.1045773320584247, 1.1044010352942952, 1.1041781333938205, 1.1039768766847879, 1.1040470477323618, 1.1038473329880165, 1.1037193452330292, 1.1038674158954653, 1.1037646391479818, 1.1035288130780552, 1.1033619298081767, 1.1033607140430877, 1.1032467167565718, 1.1029506714939465, 1.1032993165730056, 1.103365499138711, 1.1034709673661451, 1.1030613779011762, 1.1030195132630107, 1.1031193078392363)

# OpenMP
mp_loss = c(3.409805499328495, 2.0337079029125276, 1.5451913123595069, 1.3552936724298799, 1.2728972357518087, 1.2456961537900491, 1.2316137226887975, 1.2183489820258353, 1.2080618803071406, 1.209092546010379, 1.2028831474236155, 1.2034926415297875, 1.2009666071696945, 1.2045347089788063, 1.195355041361837, 1.1905411621764821, 1.1889835069183778, 1.1995746627337609, 1.1877190333818461, 1.1885992504764276, 1.1906814916074686, 1.1869440702510763, 1.1869371517079734, 1.1860882184857202, 1.1865020210930235, 1.1835623651467666, 1.188523046122437, 1.1839494765506904, 1.1849036131478115, 1.1829119670917378, 1.1842800715335111, 1.1825723377246693, 1.183171790703385, 1.1805147800533642, 1.1816079980912284, 1.1821375514893055, 1.1822203703123011, 1.1821855230560121, 1.1812465252204321, 1.1794313417936864, 1.1799459516441466, 1.1786493128027495, 1.1781632999183465, 1.1799440962633292, 1.1802756407484949, 1.1817571476610744, 1.1770997101316492, 1.1797952996796546, 1.1784367299708216, 1.1781393873541044, 1.1803253505121054, 1.1778135736274897, 1.17867548796456, 1.1754595773440883, 1.1750561496623744, 1.17803274252265, 1.1777494710417644, 1.1766771836438812, 1.1766679941794698, 1.1781972104356953, 1.175555417132816)
mp_valLoss = c(1.6298283404392615, 1.1753905509254239, 1.0176372539993062, 0.96532787597207692, 0.94844931893250128, 0.93913087762844272, 0.93368505748883213, 0.92997611132527724, 0.92775612275748287, 0.92558836551166634, 0.92390562521728647, 0.92244193338612623, 0.92123467826875582, 0.92038285499990935, 0.91966368708922397, 0.91918197535773694, 0.91854219077522981, 0.91785437923009339, 0.91724137250385784, 0.91675353635977341, 0.91634755355145958, 0.91588754215227552, 0.91546032284122936, 0.91510684419106481, 0.91476105587315215, 0.91440118710415441, 0.91397016953711019, 0.91352496006576867, 0.91319743603700221, 0.91291421910376114, 0.91271834276927122, 0.91251468274683034, 0.91230674486409125, 0.91215694978737261, 0.91195519406364878, 0.91176568359005294, 0.91164710373443814, 0.91148649137410342, 0.91132126241084155, 0.91123368906918234, 0.91115821116821361, 0.91109546341357983, 0.91103248408752879, 0.91096566063555484, 0.91087319096723918, 0.91079049476402485, 0.91066640074153704, 0.91058353788365509, 0.91054786495821471, 0.91045686744989196, 0.91035037323888057, 0.91032888888504815, 0.91033884744569837, 0.91021277530037403, 0.91016925783005453, 0.91026072373272238, 0.91040968139548906, 0.9103988734434032, 0.91033606786155896, 0.91030691268685626, 0.91032514469941084)

# Sequential
seq_loss = c(1.467226750576399, 1.2566617127965094, 1.227592972155267, 1.2063684877415637, 1.2040074260884357, 1.1987919677176107, 1.195884505251702, 1.1942001514571061, 1.1928672649287668, 1.1912332596730071, 1.1906490482401726, 1.1898255327043974, 1.1881590711205123, 1.1873432976330316, 1.1864135233988558, 1.1846658958874683, 1.1859736825636416, 1.1847755152395998, 1.1833160954726913, 1.1839680973678477, 1.1829111040301279, 1.1826227560994866, 1.1832826983235067, 1.1810990721456731, 1.1819049749174324, 1.1832260668327472, 1.1809163726262988, 1.1814110681224557, 1.1826615873223409, 1.1804102148464801)
seq_valLoss = c(0.49481278140265078, 0.4828631561382713, 0.47873092350538515, 0.47714450719708779, 0.47593886872077135, 0.47548079597033238, 0.47470596324081243, 0.47446334693730829, 0.4734875054622848, 0.47340528397491588, 0.47356588049924275, 0.47305363278632251, 0.47291309655212055, 0.47234009637566954, 0.47238303021720107, 0.47201324318371385, 0.47175889297041934, 0.47107977597056239, 0.47140009451055387, 0.47114632521214178, 0.47151265656474695, 0.47179093542625822, 0.47136645322030818, 0.47096903368299836, 0.47119108865358678, 0.47133221030925487, 0.47207262944999778, 0.47115223205233292, 0.47120055307217201, 0.47126707351627534)

n = max(length(cuda_loss), length(mp_loss), length(seq_loss))
epochs = 1:n
cuda_loss = c(cuda_loss, rep(NA,n-length(cuda_loss))); cuda_valLoss = c(cuda_valLoss, rep(NA,n-length(cuda_valLoss)))
mp_loss = c(mp_loss, rep(NA,n-length(mp_loss))); mp_valLoss = c(mp_valLoss, rep(NA,n-length(mp_valLoss)))
seq_loss = c(seq_loss, rep(NA,n-length(seq_loss))); seq_valLoss = c(seq_valLoss, rep(NA,n-length(seq_valLoss)))

### Plot training loss
png("images/ex2_trainingLoss_plot.png")
plot(epochs, seq_loss, type = "l", lwd = 2, ylim = c(min(cuda_loss, seq_loss, mp_loss, na.rm = T), 
                                                     max(cuda_loss, seq_loss, mp_loss, na.rm = T)),
     xlab = "Number of Epoch", ylab = "Training Loss")
lines(epochs, cuda_loss, col = 2, lwd = 2)
lines(epochs, mp_loss, col = 3, lwd = 2)
legend("topright", legend = c("Sequential","Cuda","OpenMP"), col = 1:3, lwd = 2)
dev.off()

### Plot validation loss
png("images/ex2_validationLoss_plot.png")
plot(epochs, seq_valLoss, type = "l", lwd = 2, ylim = c(min(cuda_valLoss, seq_valLoss, mp_valLoss, na.rm = T), 
                                                     max(cuda_valLoss, seq_valLoss, mp_valLoss, na.rm = T)),
     xlab = "Number of Epoch", ylab = "Validation Loss")
lines(epochs, cuda_valLoss, col = 2, lwd = 2)
lines(epochs, mp_valLoss, col = 3, lwd = 2)
legend("topright", legend = c("Sequential","Cuda","OpenMP"), col = 1:3, lwd = 2)
dev.off()

### Plot confidence intervals
xlabs = c("Directional Accuracy", "Hit Ratio")
model1Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(0.526206383587, 0.481200997221),
                          LowBound = c(0.447980097266, 0.360623058689),
                          UpBound = c(0.578286811884,0.606076303744),
                          Algorithm = "Sequential algorithm")
model2Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(0.498477323571, 0.474662530513),
                          LowBound = c(0.487695749441, 0.299806753458),
                          UpBound = c(0.509055318284,0.613303498779),
                          Algorithm = "OpenMP")
model3Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(0.497902989628, 0.477295362083),
                          LowBound = c(0.488097417124, 0.315439381611),
                          UpBound = c(0.508445190157,0.614732506103),
                          Algorithm = "CUDA")
# Combine these data.frames
allModelFrame <- data.frame(rbind(model1Frame, model2Frame, model3Frame))  # etc.

# Plot
png("images/ex2_accuracyAndHitRatio.png")
zp1 <- ggplot(allModelFrame, aes(colour = Algorithm))
zp1 <- zp1 + geom_hline(yintercept = 1, colour = gray(1/2), lty = 2)
zp1 <- zp1 + geom_linerange(aes(x = Metrics, ymin = LowBound, ymax = UpBound),
                            lwd = 1, position = position_dodge(width = 1/2))
zp1 <- zp1 + geom_pointrange(aes(x = Metrics, y = Estimate, ymin = LowBound,
                                 ymax = UpBound),
                             lwd = 1/2, position = position_dodge(width = 1/2),
                             shape = 21, fill = "WHITE")
zp1 <- zp1 + coord_flip() + theme_bw()
zp1 <- zp1 + ggtitle("Comparison of Algorithms")
print(zp1)
dev.off()

# MSE and MAE
xlabs = c("Mean square error", "Mean absolute error")
model1Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(1.3087405831, 0.718717655156),
                          LowBound = c(0.834318048764, 0.498239329293),
                          UpBound = c(3.23088638137,1.33780171462),
                          Algorithm = "Sequential algorithm")
model2Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(2.31100024114, 0.921309528683),
                          LowBound = c(0.838316850733, 0.525500713845),
                          UpBound = c(11.6191188956,2.56798020843),
                          Algorithm = "OpenMP")
model3Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(2.49617803848, 0.954769175157),
                          LowBound = c(0.840065719306, 0.526726699958),
                          UpBound = c(11.616296602,2.60011201977),
                          Algorithm = "CUDA")

allModelFrame <- data.frame(rbind(model1Frame, model2Frame, model3Frame))
png("images/ex2_MSEandMAE.png")
zp1 <- ggplot(allModelFrame, aes(colour = Algorithm))
zp1 <- zp1 + geom_hline(yintercept = 0, colour = gray(1/2), lty = 2)
zp1 <- zp1 + geom_linerange(aes(x = Metrics, ymin = LowBound, ymax = UpBound),
                            lwd = 1, position = position_dodge(width = 1/2))
zp1 <- zp1 + geom_pointrange(aes(x = Metrics, y = Estimate, ymin = LowBound,
                                 ymax = UpBound),
                             lwd = 1/2, position = position_dodge(width = 1/2),
                             shape = 21, fill = "WHITE")
zp1 <- zp1 + coord_flip() + theme_bw()
zp1 <- zp1 + ggtitle("Comparison of Algorithms")
print(zp1)
dev.off()

#### Experiment 4 Hessian-Free
# Cuda
cuda_loss = c(1.565016429669537, 1.3142119318509204, 1.2551753065905067, 1.2363958944996583, 1.2310365140047326, 1.2269748800435456, 1.2285545747348772, 1.2264781225384707, 1.2244665228628537, 1.2214250217058205, 1.2245545345452353, 1.2188701528651695, 1.2204451327851522, 1.2193338418194866, 1.2200314313782767, 1.2198468162222329, 1.21799619414597, 1.2196180421064133, 1.2174114943269241, 1.2173559003032828, 1.2164036436907666, 1.2149890678554578, 1.2168772177983904, 1.2166541055615452, 1.2168817204148785, 1.2153135794435574, 1.2172052857002038, 1.2159806417304881, 1.2156058380507047, 1.2148386708696708, 1.2161772875908676, 1.2151173406926352, 1.2143086288092924, 1.2148957654958379, 1.2151109878688886, 1.2135543054523235, 1.2146850180860977, 1.2130851431216265)
cuda_valLoss = c(0.52792000928096283, 0.50230332247836251, 0.49103443909711275, 0.48377753305269533, 0.4809806459760903, 0.4786507877502249, 0.47703165280365034, 0.47684796860429007, 0.47635053110077208, 0.47538334449137698, 0.47459120153934198, 0.47471490118485871, 0.47391448412480047, 0.47416459975714548, 0.47343613178818844, 0.473739285733279, 0.47337722522947234, 0.47342088158193496, 0.47347601625187086, 0.4730867660303027, 0.47322335275542582, 0.47246396795344542, 0.4730221190217746, 0.47290043518333913, 0.47294925593053372, 0.47271207399860682, 0.4725320589500977, 0.47220698851394471, 0.47254267545448292, 0.47235912153599219, 0.47173560271835741, 0.47151723020725211, 0.47194094529927211, 0.47191520277952498, 0.47166792566157045, 0.47176682953938143, 0.4719264926690187, 0.47155476320050538)

# OpenMP
mp16_loss = c(1.8256682226299268, 1.3218321030761921, 1.2657124283856664, 1.2450576970445988, 1.2446758356245708, 1.2359806746911757, 1.2327995006365047, 1.2308067089864558, 1.2274803584986917, 1.2281529920757266, 1.2256931520578924, 1.2254862473081536, 1.2234877650765004, 1.222465954715265, 1.22230380294795, 1.2202177972831092, 1.2196661715249548, 1.2219613972745367, 1.2206135170281565, 1.2180570547459779, 1.2191092211833121, 1.2208922621823304, 1.2186795921470781, 1.2189334816751773, 1.2194885603749495, 1.219105385616758, 1.21799163022785, 1.2173678800005683, 1.2187822072181209, 1.2176109915215927, 1.2158759172688585, 1.2172815214374351)
mp16_valLoss = c(0.53813304876600732, 0.49898632739075977, 0.48746870228432398, 0.48369317051175748, 0.48043168304840395, 0.47867560325757935, 0.4773257697572923, 0.47601104339683797, 0.47495464371299967, 0.47499653187282698, 0.47427813555822246, 0.47425931646245578, 0.47433484609522814, 0.47356637196858808, 0.47316551205248103, 0.47328172815031988, 0.47270214774044922, 0.47243443935932933, 0.47256570443024826, 0.47231214165923041, 0.47209625607184513, 0.47202766075193392, 0.47181600440661742, 0.47186066942183785, 0.47127355613140748, 0.4711564504907807, 0.47128856457771395, 0.47148704467096819, 0.47134156518943565, 0.47191179728006183, 0.47224349589400133, 0.47157388862622596)

mp64_loss = c(1.7550187717005425, 1.3372043929308384, 1.2863338827611859, 1.2687803906313047, 1.2516866095878798, 1.2505389827225866, 1.2324491081903677, 1.2331882422373137, 1.228118859881417, 1.2274813576059831, 1.226629631155399, 1.224632855637138, 1.2235712644111061, 1.2215129537049105, 1.2226333456524003, 1.2190010034634249, 1.2191487406390069, 1.2218399531949633, 1.2195936353029995, 1.2186986259135537, 1.2204855282749552, 1.2195856653854589, 1.218305425435289, 1.2161347397549827, 1.2164286388706929, 1.2159162988092647, 1.2171638241411322, 1.2151692403010967, 1.2174206298016363, 1.2164489898676445, 1.2162925097339354, 1.2151036434788884, 1.2157393443932973)
mp64_valLoss = c(0.50328868306403374, 0.48792955745233596, 0.48155884748501998, 0.4785042224337332, 0.47604977092709788, 0.47589097194504032, 0.47506386807354473, 0.47310093438038264, 0.47284475364555789, 0.47265371114094751, 0.47232114179007212, 0.47205939547306397, 0.47170986707622548, 0.47137489731585763, 0.47079992875295423, 0.47103924523029361, 0.47053394758297762, 0.47040960987016489, 0.47035830605217632, 0.47033661471978089, 0.47008837407798554, 0.47014465067969802, 0.46993221262074419, 0.46960238212379918, 0.46992023989855614, 0.46968216603656987, 0.46930815581851204, 0.4696393504015115, 0.46997840815299813, 0.46945107398927316, 0.46956127204392228, 0.46963667937369624, 0.46980342420584237)

# Sequential
seq_loss = c(1.9723429999831854, 1.3754175297541293, 1.3376061790873732, 1.2746191690035786, 1.2631476142623377, 1.2516381835924102, 1.24757458260081, 1.2388902119197949, 1.2344052253502342, 1.2314713024879129, 1.2312916304809511, 1.2245766827246856, 1.2256223406843572, 1.2220312692692488, 1.2227997502066035, 1.2239135339672698, 1.2224045311113421, 1.2205263670092839, 1.2203179959398138, 1.2217431497173559, 1.2197952987038321, 1.2196300642984097, 1.218200763487135, 1.2163162712640643, 1.2170532377295966, 1.218823976043516, 1.2166619603661122, 1.2171644744404224, 1.2159686780510564, 1.2165754117059069, 1.2151360172016969, 1.2128855662690399, 1.2169340714929759, 1.2140697671460263, 1.2160363069108724, 1.2141288989555696, 1.2163547446154634, 1.2170676779283789, 1.213590940320088, 1.2153712956613101, 1.2134358402317689, 1.2146660656217498, 1.2146773641786273)
seq_valLoss = c(0.56016299845728823, 0.50651573853875675, 0.49834189507708093, 0.49416927543146705, 0.49193217166315739, 0.49055695679911915, 0.48617929606304189, 0.48673111426473825, 0.48497859074499244, 0.48476902577526426, 0.48478194666236862, 0.48161094287429029, 0.4809356811512524, 0.48173419491048325, 0.48053195948139882, 0.47946715710980148, 0.47831131963166007, 0.4776552447294411, 0.47617238303652154, 0.47511809212124873, 0.47543930618032659, 0.47521927899783611, 0.47448014539867128, 0.47446282195278394, 0.4738721411857153, 0.47410916932133756, 0.47443809123822334, 0.47424937389127714, 0.47337661880164206, 0.47338586988829762, 0.47351091392893985, 0.47307537973239711, 0.47390855209646021, 0.47349646740896434, 0.4728694430051078, 0.47325409474112051, 0.47278013981117001, 0.47304726044039225, 0.47325925374419203, 0.47357266111323881, 0.4738842572091459, 0.47408273826055669, 0.47414244337372929)

# Hessian
hes_valLoss = c(0.23822556946230475, 0.23650290962020362, 0.23513778235785765, 0.23606774062910943, 0.23697069923153471, 0.24483997958360218, 0.23274376326053761, 0.23452026176530508, 0.24374483426091495, 0.23664583309545736, 0.23422947087938448, 0.23287581577734032, 0.23200900804992228, 0.23269670224814976, 0.23221523320987017, 0.23320547733834829)

n = max(length(cuda_loss), length(mp16_loss), length(mp16_loss), length(seq_loss), length(hes_valLoss))
epochs = 1:n
cuda_loss = c(cuda_loss, rep(NA,n-length(cuda_loss))); cuda_valLoss = c(cuda_valLoss, rep(NA,n-length(cuda_valLoss)))
mp16_loss = c(mp16_loss, rep(NA,n-length(mp16_loss))); mp16_valLoss = c(mp16_valLoss, rep(NA,n-length(mp16_valLoss)))
mp64_loss = c(mp64_loss, rep(NA,n-length(mp64_loss))); mp64_valLoss = c(mp64_valLoss, rep(NA,n-length(mp64_valLoss)))
seq_loss = c(seq_loss, rep(NA,n-length(seq_loss))); seq_valLoss = c(seq_valLoss, rep(NA,n-length(seq_valLoss)))
hes_valLoss = c(hes_valLoss, rep(NA,n-length(hes_valLoss)))

### Plot training loss
png("images/ex4_trainingLoss_plot.png")
plot(epochs, seq_loss, type = "l", lwd = 2, ylim = c(min(cuda_loss, seq_loss, mp16_loss, mp64_loss, na.rm = T), 
                                                     max(cuda_loss, seq_loss, mp16_loss, mp64_loss, na.rm = T)),
     xlab = "Number of Epoch", ylab = "Training Loss", main = "Experiment 2")
lines(epochs, cuda_loss, col = 2, lwd = 2)
lines(epochs, mp16_loss, col = 3, lwd = 2)
lines(epochs, mp64_loss, col = 4, lwd = 2)
legend("topright", legend = c("Sequential","Cuda","OpenMP 16 cores", "OpenMP 64 cores"), col = 1:4, lwd = 2)
dev.off()

### Plot validation loss
png("images/ex4_validationLoss_plot.png")
plot(epochs, seq_valLoss, type = "l", lwd = 2, ylim = c(min(cuda_valLoss, seq_valLoss, mp16_valLoss, mp64_valLoss, na.rm = T), 
                                                        max(cuda_valLoss, seq_valLoss, mp16_valLoss, mp64_valLoss, na.rm = T)),
     xlab = "Number of Epoch", ylab = "Validation Loss")
lines(epochs, cuda_valLoss, col = 2, lwd = 2)
lines(epochs, mp16_valLoss, col = 3, lwd = 2)
lines(epochs, mp64_valLoss, col = 4, lwd = 2)
lines(epochs, hes_valLoss, col = 5, lwd = 2)
legend("topright", legend = c("Sequential","Cuda","OpenMP 16 cores", "OpenMP 64 cores", "Hessian-Free"), col = 1:5, lwd = 2)
dev.off()

### Plot confidence intervals
xlabs = c("Accuracy", "Hit Ratio")
model1Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(0.526206383587, 0.481200997221),
                          LowBound = c(0.447980097266, 0.360623058689),
                          UpBound = c(0.578286811884,0.606076303744),
                          Algorithm = "Sequential algorithm")
model2Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(0.498477323571, 0.474662530513),
                          LowBound = c(0.487695749441, 0.299806753458),
                          UpBound = c(0.509055318284,0.613303498779),
                          Algorithm = "OpenMP")
model3Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(0.497902989628, 0.477295362083),
                          LowBound = c(0.488097417124, 0.315439381611),
                          UpBound = c(0.508445190157,0.614732506103),
                          Algorithm = "CUDA")
# Combine these data.frames
allModelFrame <- data.frame(rbind(model1Frame, model2Frame, model3Frame))  # etc.

# Plot
png("images/ex2_accuracyAndHitRatio.png")
zp1 <- ggplot(allModelFrame, aes(colour = Algorithm))
zp1 <- zp1 + geom_hline(yintercept = 1, colour = gray(1/2), lty = 2)
zp1 <- zp1 + geom_linerange(aes(x = Metrics, ymin = LowBound, ymax = UpBound),
                            lwd = 1, position = position_dodge(width = 1/2))
zp1 <- zp1 + geom_pointrange(aes(x = Metrics, y = Estimate, ymin = LowBound,
                                 ymax = UpBound),
                             lwd = 1/2, position = position_dodge(width = 1/2),
                             shape = 21, fill = "WHITE")
zp1 <- zp1 + coord_flip() + theme_bw()
zp1 <- zp1 + ggtitle("Comparison of Algorithms")
print(zp1)
dev.off()

# MSE and MAE
xlabs = c("Mean square error", "Mean absolute error")
model1Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(1.3087405831, 0.718717655156),
                          LowBound = c(0.834318048764, 0.498239329293),
                          UpBound = c(3.23088638137,1.33780171462),
                          Algorithm = "Sequential algorithm")
model2Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(2.31100024114, 0.921309528683),
                          LowBound = c(0.838316850733, 0.525500713845),
                          UpBound = c(11.6191188956,2.56798020843),
                          Algorithm = "OpenMP")
model3Frame <- data.frame(Metrics = xlabs,
                          Estimate = c(2.49617803848, 0.954769175157),
                          LowBound = c(0.840065719306, 0.526726699958),
                          UpBound = c(11.616296602,2.60011201977),
                          Algorithm = "CUDA")

allModelFrame <- data.frame(rbind(model1Frame, model2Frame, model3Frame))
png("images/ex2_MSEandMAE.png")
zp1 <- ggplot(allModelFrame, aes(colour = Algorithm))
zp1 <- zp1 + geom_hline(yintercept = 0, colour = gray(1/2), lty = 2)
zp1 <- zp1 + geom_linerange(aes(x = Metrics, ymin = LowBound, ymax = UpBound),
                            lwd = 1, position = position_dodge(width = 1/2))
zp1 <- zp1 + geom_pointrange(aes(x = Metrics, y = Estimate, ymin = LowBound,
                                 ymax = UpBound),
                             lwd = 1/2, position = position_dodge(width = 1/2),
                             shape = 21, fill = "WHITE")
zp1 <- zp1 + coord_flip() + theme_bw()
zp1 <- zp1 + ggtitle("Comparison of Algorithms")
print(zp1)
dev.off()

